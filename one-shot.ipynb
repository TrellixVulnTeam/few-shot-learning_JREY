{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Few-Shot Learning\n",
    "\n",
    "**Challenge:** [Omniglot](https://github.com/brendenlake/omniglot), the \"transpose\" of MNIST, with 1,623 character classes, each with 20 examples. Build a few-shot classifier with a target of <35% error.\n",
    "\n",
    "## Exploring the Dataset\n",
    "\n",
    "**[Omniglot](https://github.com/brendenlake/omniglot)** is a collection of 1,623 hand drawn characters from 50 alphabets. Each of the 1,623 characters is drawn online via *Amazon's Mechanical Turk* by 20 different people at resolution of `105x105`. It is sometimes reffered to as the **\"Trasnpose of MNIST\"**, since it has 1,623 types of character with only 20 examples each, in contrast to MNIST having thousands of examples for only 10 digits.\n",
    "\n",
    "Data Structure:\n",
    "```sh\n",
    "$ tree all_runs/ -L 2\n",
    " all_runs\n",
    "├── run01\n",
    "│   ├── class_labels.txt\n",
    "│   ├── test\n",
    "│   └── training\n",
    "├── run02\n",
    "│   ├── class_labels.txt\n",
    "│   ├── test\n",
    "│   └── training\n",
    "├── run03\n",
    "│   ├── class_labels.txt\n",
    "│   ├── test\n",
    "│   └── training\n",
    "│\n",
    "├── ...\n",
    "│\n",
    "├── run18\n",
    "│   ├── class_labels.txt\n",
    "│   ├── test\n",
    "│   └── training\n",
    "├── run19\n",
    "│   ├── class_labels.txt\n",
    "│   ├── test\n",
    "│   └── training\n",
    "└── run20\n",
    "    ├── class_labels.txt\n",
    "    ├── test\n",
    "    └── training\n",
    "\n",
    "60 directories, 20 files\n",
    "```\n",
    "\n",
    "Omniglot contains 20 examples called \"runs\" each run has `class_labels.txt`, `test` and `training` folders. Let's see what's going on visually:\n",
    "\n",
    "```sh\n",
    "$ tree all_runs/run0\n",
    "all_runs/run01\n",
    "├── class_labels.txt\n",
    "├── test\n",
    "│   ├── item01.png\n",
    "│   ├── item02.png\n",
    "│   ├── item03.png\n",
    "│   ├── item04.png\n",
    "│   ├── ...\n",
    "│   ├── item17.png\n",
    "│   ├── item18.png\n",
    "│   ├── item19.png\n",
    "│   └── item20.png\n",
    "└── training\n",
    "    ├── class01.png\n",
    "    ├── class02.png\n",
    "    ├── class03.png\n",
    "    ├── ...\n",
    "    ├── class17.png\n",
    "    ├── class18.png\n",
    "    ├── class19.png\n",
    "    └── class20.png\n",
    "\n",
    "2 directories, 41 files\n",
    "```\n",
    "\n",
    "### N-way One-shot learning\n",
    "\n",
    "Given a tiny labelled training set $S$, which has $ N $ examples, each vectors of the same dimension with a distinct label $y$.\n",
    "\n",
    "$$ S = \\{(x_i, y_i), ..., (x_N, y_N)\\} $$\n",
    "\n",
    "We're also given $\\hat{x}$, the test example it has to classify. Since exactly one example in the training set has the right class, the aim is to correctly predict which $y \\in S$ is the same as $\\hat{x}$'s label, $\\hat{y}$.\n",
    "\n",
    "- Real world problems might not always have the constraint that exactly one image has the correct class.\n",
    "\n",
    "- It's easy to generalize to k-shot learning by having there be $k$ examples for each $y_i$ rather than just one.\n",
    "\n",
    "- When $N$ is higher, there are more possible classes that $\\hat{x}$ can belong to, so it's harder to predict the correct one.\n",
    "\n",
    "- Randomly guessing will average ${100\\over n}\\%$ accuracy.\n",
    "\n",
    "\n",
    "Let's visualze some examples in the Omniglot dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Data directory.\n",
    "# data_dir = omniglot.data_dir\n",
    "\n",
    "# # Directory containing compressed files.\n",
    "# comp_dir = omniglot.compressed_dir\n",
    "\n",
    "# # Extract `all_runs`.\n",
    "# all_runs_dir = omniglot.Data.extract(os.path.join(comp_dir, 'all_runs.tar.gz'))\n",
    "# image_bg_dir = omniglot.Data.extract(os.path.join(comp_dir, 'images_background.tar.gz'))\n",
    "\n",
    "# # Visualize 1st run.\n",
    "# # Emphasis 1st matching digits in \"class_labels.txt\".\n",
    "# omniglot.Visualize.runs(directory=os.path.join(all_runs_dir, 'run01'),\n",
    "#                         index=0,  # Index to emphasize on.\n",
    "#                         title='Visualize 1st matching digits')\n",
    "\n",
    "# # Visualize one random character from 20 different classes of Greek alphabet.\n",
    "# omniglot.Visualize.symbols(directory=os.path.join(image_bg_dir, 'Greek'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# For OS operations.\n",
    "import os\n",
    "\n",
    "# Dataset helper.\n",
    "import omniglot\n",
    "\n",
    "# Model helper.\n",
    "import model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracing datasets/compressed/images_background.tar.gz...\n",
      "Sucessfully extracted to datasets/extracted/images_background\n",
      "Loading cached images & corresponding targets.\n",
      "Extracing datasets/compressed/images_evaluation.tar.gz...\n",
      "Sucessfully extracted to datasets/extracted/images_evaluation\n",
      "Loading cached images & corresponding targets.\n",
      "\n",
      "Training data: (964, 105, 105, 1)\n",
      "train_data = Dataset(mode='TRAIN', cache=True, cache_dir='saved/images_background/train')\n",
      "\n",
      "Validation data: (659, 105, 105, 1)\n",
      "val_data = Dataset(mode='VALIDATE', cache=True, cache_dir='saved/images_evaluation/validate')\n"
     ]
    }
   ],
   "source": [
    "train_path = os.path.join(omniglot.compressed_dir, 'images_background.tar.gz')\n",
    "val_path = os.path.join(omniglot.compressed_dir, 'images_evaluation.tar.gz')\n",
    "\n",
    "# To avoid writing `omniglot.Dataset`...\n",
    "Dataset = omniglot.Dataset\n",
    "\n",
    "# Create training & validation data instance.\n",
    "train_data = Dataset(path=train_path, mode=Dataset.Mode.TRAIN)\n",
    "val_data = Dataset(path=val_path, mode=Dataset.Mode.VALIDATE)\n",
    "\n",
    "print(f'\\nTraining data: {train_data.shape}')\n",
    "print(f'train_data = {train_data}')\n",
    "\n",
    "print(f'\\nValidation data: {val_data.shape}')\n",
    "print(f'val_data = {val_data}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Function has keyword-only parameters or annotations, use getfullargspec() API which can support them",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-2b27dd8dc78c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnetwork\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSiameseNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# network.compile(optimizer='adam',\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#                 loss=network.contractive_loss)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Code/IPython projects/few-shot-learning/model.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, num_classes, **kwargs)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSiameseNetwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;31m# Positional Arguments.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m     \u001b[0;31m# Create a cache for iterator get_next op.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_get_next\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWeakKeyDictionary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/keras/engine/network.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m       \u001b[0;31m# Subclassed network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_subclassed_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_base_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/keras/engine/network.py\u001b[0m in \u001b[0;36m_init_subclassed_network\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    296\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_base_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_graph_network\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 298\u001b[0;31m     \u001b[0mcall_argspec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_inspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetargspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'training'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcall_argspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_expects_training_arg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/util/tf_inspect.py\u001b[0m in \u001b[0;36mgetargspec\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m     73\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;31m# Python3 will handle most callables here (not partial).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_inspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetargspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/inspect.py\u001b[0m in \u001b[0;36mgetargspec\u001b[0;34m(func)\u001b[0m\n\u001b[1;32m   1073\u001b[0m         \u001b[0mgetfullargspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1074\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkwonlyargs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mann\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1075\u001b[0;31m         raise ValueError(\"Function has keyword-only parameters or annotations\"\n\u001b[0m\u001b[1;32m   1076\u001b[0m                          \", use getfullargspec() API which can support them\")\n\u001b[1;32m   1077\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mArgSpec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvarargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvarkw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Function has keyword-only parameters or annotations, use getfullargspec() API which can support them"
     ]
    }
   ],
   "source": [
    "network = model.SiameseNetwork()\n",
    "\n",
    "# network.compile(optimizer='adam',\n",
    "#                 loss=network.contractive_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring Models\n",
    "\n",
    "### One-Shot Learning Baseline over Nearest Neighbor\n",
    "\n",
    "The simplest way to perform classification is with **K-Nearest Neighbors**, but since there are only one example per class, we're only allowed 1 nearest neighbor lookup –which is really bad! K-Nearest Neigbors usually performs well with 5 neighbors or more *(but this also depends on dataset & it's sparsity)*.\n",
    "\n",
    "Nearest Neighbor: This is just a way of measuring distance in a higher dimensional plane using distance metrics such as [Euclidean Distance]().\n",
    "\n",
    "$$ \\textrm{Euclidean Distance} = \\sqrt{\\sum_i^n{(q_i - p_i)^2}}$$\n",
    "\n",
    "After calculating the Euclidean disance over `k` nearest neighbors. We then take the closest one:\n",
    "\n",
    "$$ C(\\hat{x}) = \\underset{c \\in S}{\\operatorname{argmax}} \\big\\|\\hat{x} - x_c\\big\\| $$\n",
    "\n",
    "After calculating the Euclidean disance over `k` nearest neighbors. We then take the closest one:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
